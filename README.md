# Fine-tuning de modÃ¨les multilingues auto-supervisÃ©s pour la transcription de la parole en langue camerounaise : le Yemba

## ğŸ“Œ Contexte du projet
Ce projet sâ€™inscrit dans le cadre du hackathon **Aurore de la Recherche**, organisÃ© Ã  lâ€™**UniversitÃ© de YaoundÃ© I**.  
Lâ€™objectif principal du hackathon Ã©tait de promouvoir lâ€™utilisation de lâ€™intelligence artificielle et des mÃ©thodes modernes dâ€™apprentissage automatique pour la valorisation des **langues locales camerounaises**, en particulier dans le domaine du traitement automatique de la parole.

## ğŸ¯ Objectif
La tÃ¢che assignÃ©e consistait Ã  rÃ©aliser le **fine-tuning dâ€™un modÃ¨le multilingue auto-supervisÃ©** pour la **transcription automatique de la parole** en langue **Yemba**, une langue camerounaise peu dotÃ©e en ressources numÃ©riques.

Plus prÃ©cisÃ©ment, il sâ€™agissait de :
- sÃ©lectionner un modÃ¨le multilingue adaptÃ© Ã  la reconnaissance automatique de la parole (ASR),
- lâ€™adapter (fine-tuning) Ã  un jeu de donnÃ©es spÃ©cifique au Yemba,
- Ã©valuer sa capacitÃ© Ã  transcrire correctement la parole en Yemba.

## ğŸ“Š Jeu de donnÃ©es
Le projet utilise le jeu de donnÃ©es **YembaEGRA**, disponible publiquement sur Mendeley Data :

ğŸ”— **Lien du dataset** :  
https://data.mendeley.com/datasets/74p9d5frg3/1

Ce corpus contient des enregistrements audio annotÃ©s en langue Yemba, conÃ§us pour des tÃ¢ches de reconnaissance et de transcription de la parole.

## ğŸ§  ModÃ¨le utilisÃ©
AprÃ¨s plusieurs expÃ©rimentations avec diffÃ©rents modÃ¨les multilingues, nous avons retenu le modÃ¨le **Whisper**, dÃ©veloppÃ© par OpenAI.

Les raisons de ce choix incluent :
- sa robustesse sur des langues peu dotÃ©es,
- sa capacitÃ© Ã  gÃ©rer des donnÃ©es multilingues,
- ses performances Ã©levÃ©es en reconnaissance automatique de la parole,
- sa facilitÃ© dâ€™adaptation par fine-tuning.

## âš™ï¸ MÃ©thodologie
Le travail prÃ©sentÃ© dans ce projet comprend :
1. La prÃ©paration et le prÃ©traitement du jeu de donnÃ©es YembaEGRA  
2. Lâ€™adaptation du modÃ¨le Whisper au corpus Yemba  
3. Le fine-tuning du modÃ¨le sur les donnÃ©es audio annotÃ©es  
4. Lâ€™analyse des rÃ©sultats obtenus en transcription automatique  

## ğŸ“’ Contenu du dÃ©pÃ´t
Ce dÃ©pÃ´t contient principalement :
- un **notebook Jupyter** dÃ©taillant toutes les Ã©tapes du travail,
- le code de prÃ©paration des donnÃ©es,
- les scripts de fine-tuning du modÃ¨le Whisper,
- ainsi que les analyses et rÃ©sultats obtenus.


---

**Auteur :** Kamga Mawabo Ines, Nono Ngansoap Nahomie  

